{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cedccd94-f49f-4646-8766-994f654a50a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools as ft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d147736b-8218-4847-9d71-3ae2cf66bd3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnimalType      int64\n",
       "Class           int64\n",
       "Fat             int64\n",
       "Weight        float64\n",
       "AgeMonths     float64\n",
       "Remark         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching data\n",
    "carcass_df = pd.read_csv('UnderSampledDataSet.csv')\n",
    "\n",
    "# Removing data not used in training models \n",
    "X = carcass_df.copy()\n",
    "X = X.drop(['Group', \n",
    "            'Killnumber', \n",
    "            'KillDate', \n",
    "            'WeightWarm', \n",
    "            'ClassificationTime', \n",
    "            'PartCassation'], axis=1)\n",
    "\n",
    "# Normalizing the numerical data \n",
    "X[['Weight', 'AgeMonths']] = preprocessing.normalize(\n",
    "    X[['Weight', 'AgeMonths']])\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e335c8ab-ca7f-4843-8a86-69ae8ee7ae4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3002\n",
      "18809\n",
      "47212\n",
      "0.3983944759806829\n",
      "Remark\n",
      "589         8037\n",
      "590         4367\n",
      "588         3830\n",
      "338\\n589    1328\n",
      "339\\n589    1247\n",
      "113\\n589     837\n",
      "77\\n589      803\n",
      "340\\n589     777\n",
      "339\\n588     733\n",
      "338\\n588     710\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "7     8083\n",
      "6     7465\n",
      "8     6778\n",
      "5     6681\n",
      "9     5374\n",
      "4     3941\n",
      "10    3923\n",
      "11    2406\n",
      "3     1031\n",
      "12     913\n",
      "Name: count, dtype: int64\n",
      "Fat\n",
      "6     12538\n",
      "5      9695\n",
      "7      9330\n",
      "4      4566\n",
      "8      4119\n",
      "9      2736\n",
      "3      2074\n",
      "10      926\n",
      "2       755\n",
      "11      300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(X['Remark'].unique()))\n",
    "sumRemarkTop5Count = sum(X['Remark'].value_counts().head(5))\n",
    "sumRemarkCount = sum(X['Remark'].value_counts())\n",
    "print(sumRemarkTop5Count)\n",
    "print(sumRemarkCount)\n",
    "print(sumRemarkTop5Count/sumRemarkCount)\n",
    "print(X['Remark'].value_counts().head(10))\n",
    "print(X['Class'].value_counts().head(10))\n",
    "print(X['Fat'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c68964-0d55-45aa-97bc-92c1e93eb483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight                float64\n",
      "AgeMonths             float64\n",
      "(Remark, 113\\n589)       bool\n",
      "(Remark, 338\\n588)       bool\n",
      "(Remark, 338\\n589)       bool\n",
      "(Remark, 339\\n588)       bool\n",
      "(Remark, 339\\n589)       bool\n",
      "(Remark, 339\\n590)       bool\n",
      "(Remark, 340\\n589)       bool\n",
      "(Remark, 588)            bool\n",
      "(Remark, 589)            bool\n",
      "(Remark, 590)            bool\n",
      "(Remark, 77\\n589)        bool\n",
      "(Remark, 77\\n590)        bool\n",
      "(Class, 4)               bool\n",
      "(Class, 5)               bool\n",
      "(Class, 6)               bool\n",
      "(Class, 7)               bool\n",
      "(Class, 8)               bool\n",
      "(Class, 9)               bool\n",
      "(Class, 10)              bool\n",
      "(Class, 11)              bool\n",
      "(Fat, 3)                 bool\n",
      "(Fat, 4)                 bool\n",
      "(Fat, 5)                 bool\n",
      "(Fat, 6)                 bool\n",
      "(Fat, 7)                 bool\n",
      "(Fat, 8)                 bool\n",
      "(Fat, 9)                 bool\n",
      "(Fat, 10)                bool\n",
      "(AnimalType, 212)        bool\n",
      "(AnimalType, 216)        bool\n",
      "(AnimalType, 218)        bool\n",
      "(AnimalType, 219)        bool\n",
      "(AnimalType, 222)        bool\n",
      "(AnimalType, 224)        bool\n",
      "dtype: object\n",
      "bool       34\n",
      "float64     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding for categorical data\n",
    "\n",
    "# Using One Hot Encoding to add the top ten remarks as binary features \n",
    "remark_sorted = X['Remark'].value_counts()\n",
    "top_remarks = []\n",
    "nr_of_remarks = 12\n",
    "for key in range(nr_of_remarks):\n",
    "    top_remarks.append(remark_sorted.keys()[key])\n",
    "    \n",
    "df_encoded = pd.get_dummies(X['Remark'], columns=['Remark'])\n",
    "for col in df_encoded.columns:\n",
    "    if col in top_remarks:\n",
    "        X['Remark',col] = df_encoded[col]\n",
    "\n",
    "X = X.drop(['Remark'], axis=1)\n",
    "\n",
    "# Using One Hot Encoding to add the top ten Classes as binary features \n",
    "class_sorted = X['Class'].value_counts()\n",
    "top_class = []\n",
    "nr_of_classes = 8\n",
    "for key in range(nr_of_classes):\n",
    "    top_class.append(class_sorted.keys()[key])\n",
    "        \n",
    "df_encoded = pd.get_dummies(X['Class'], columns=['Class'])\n",
    "for col in df_encoded.columns:\n",
    "    if col in top_class:\n",
    "        X['Class',col] = df_encoded[col]\n",
    "\n",
    "X = X.drop(['Class'], axis=1)\n",
    "\n",
    "# Using One Hot Encoding to add the top ten Fats as binary features \n",
    "fat_sorted = X['Fat'].value_counts()\n",
    "top_fat = []\n",
    "nr_of_fats = 8\n",
    "for key in range(nr_of_fats):\n",
    "    top_fat.append(fat_sorted.keys()[key])\n",
    "        \n",
    "df_encoded = pd.get_dummies(X['Fat'], columns=['Fat'])\n",
    "for col in df_encoded.columns:\n",
    "    if col in top_fat:\n",
    "        X['Fat',col] = df_encoded[col]\n",
    "\n",
    "X = X.drop(['Fat'], axis=1)\n",
    "\n",
    "# Using One Hot Encoding to add AnimalType as binary features \n",
    "df_encoded = pd.get_dummies(X['AnimalType'], columns=['AnimalType'])\n",
    "for col in df_encoded.columns:\n",
    "    X['AnimalType',col] = df_encoded[col]\n",
    "\n",
    "X = X.drop(['AnimalType'], axis=1)\n",
    "print(X.dtypes)\n",
    "print(X.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50879d6d-a23a-4188-b34b-d5449da55cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9980564846305773, 0.06231575632899144, False, ..., False, True,\n",
       "        False],\n",
       "       [0.9975599617888159, 0.06981491700128503, False, ..., False,\n",
       "        False, False],\n",
       "       [0.9978052958341178, 0.0662162488018512, False, ..., False, True,\n",
       "        False],\n",
       "       ...,\n",
       "       [0.9980059138553454, 0.06312048724270698, False, ..., False,\n",
       "        False, True],\n",
       "       [0.9987950661447739, 0.049075613545393554, False, ..., False,\n",
       "        True, False],\n",
       "       [0.9990400346134506, 0.04380649768648041, False, ..., False, True,\n",
       "        False]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the dataset into matrix\n",
    "X = X.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78634091-fec8-4979-b5fc-b008c61091ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 10, 10, 10], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = carcass_df['Group'].to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c545c54-f802-4da2-b75e-2b6141bbcf45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd99ff73-9c85-4d14-950c-d40e2d365709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_default = MLPClassifier(max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b0c4d8-0dcd-4e50-9d0b-501329b288dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(max_iter=1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bff79b33-10b5-4bd7-ba4f-eb4b1565e305",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default.n_layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8251f00d-6a6f-41c9-86d5-d31d0e51c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_default = model_default.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f27456-7c11-4b38-9a89-28f403f56824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9706661018744043"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bed680b-7bc4-4704-974f-274a78a540c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>817</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>785</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>833</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>804</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>805</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0    1    2    3    4    5    6    7    8    9    10\n",
       "row_0                                                       \n",
       "0      813    0    0   14    0    2    5    0    8    7    9\n",
       "1        0  892    7    0    0    0    0    3    4    1   17\n",
       "2        0    8  817    0    0    3    0    1    7    7    7\n",
       "3        2    0    1  785    6    1   12    2    0    1    1\n",
       "4        0    0    0    0  833    2    5    0    1    0    0\n",
       "5        0    0    0    1    8  899    2    0    0    0    0\n",
       "6        2    0    0    5    6    2  807    0    0    0    1\n",
       "7        1    6    1    1    1    2    1  870    1    1    9\n",
       "8        1    5    3    0    2    0    0    0  804    3   10\n",
       "9       14    2    4    2    0    0    0    1    4  805   12\n",
       "10       1    1    3    0    0    0    1    2    5    6  841"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, predictions_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3a07040-4b68-4fe7-aa07-5cbf7026ae8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       858\n",
      "           1       0.98      0.97      0.97       924\n",
      "           2       0.98      0.96      0.97       850\n",
      "           3       0.97      0.97      0.97       811\n",
      "           4       0.97      0.99      0.98       841\n",
      "           5       0.99      0.99      0.99       910\n",
      "           6       0.97      0.98      0.97       823\n",
      "           7       0.99      0.97      0.98       894\n",
      "           8       0.96      0.97      0.97       828\n",
      "           9       0.97      0.95      0.96       844\n",
      "          10       0.93      0.98      0.95       860\n",
      "\n",
      "    accuracy                           0.97      9443\n",
      "   macro avg       0.97      0.97      0.97      9443\n",
      "weighted avg       0.97      0.97      0.97      9443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, predictions_default))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
