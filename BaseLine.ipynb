{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda643ac-ed3f-4839-af01-3e658689508b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232eeeed-1386-4caa-bf70-2b79d6981347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clusters: 11\n",
      "size of pop: 47212\n"
     ]
    }
   ],
   "source": [
    "carcass_df = pd.read_csv('UnderSampledDataSet.csv')\n",
    "# Number of classes\n",
    "C = carcass_df['Group'].nunique()\n",
    "# Size of population\n",
    "P = len(carcass_df)\n",
    "print('number of clusters:', C)\n",
    "print('size of pop:', P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d9b3c4-425a-4847-97f6-86669f34e7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP are: 390.1818181818182\n",
      "FP are: 3901.8181818181815\n",
      "FN are: 3901.818181818182\n",
      "TN are: 39018.181818181816\n",
      "Together they are the population: 47212.0\n"
     ]
    }
   ],
   "source": [
    "# Formulas from Performance metrics in report \n",
    "TP = P/C * 1/C \n",
    "FP = P/C * (1 - 1/C)\n",
    "FN = (P - P/C) * 1/C\n",
    "TN = (P - P/C) * (1 - 1/C)\n",
    "print('TP are:', TP)\n",
    "print('FP are:', FP)\n",
    "print('FN are:', FN)\n",
    "print('TN are:', TN)\n",
    "print('Together they are the population:', TP + FP + FN + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07338a4-4bb8-48cc-848a-4f5e1da13040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8347107438016528\n"
     ]
    }
   ],
   "source": [
    "# Average Accuracy\n",
    "average_accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "print(average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea50a06f-676a-4606-abf3-a8f140b7b7ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Precision \n",
    "Precision = TP/(TP+FP)\n",
    "print(Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0bebc98-cbbc-45f3-bd18-165558d7e22b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Recall \n",
    "Recall = TP/(TP+FN)\n",
    "print(Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82218758-247d-4e5a-b24b-d0c1e39a5e84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "f1_score = 2*((Recall * Precision)/(Recall + Precision))\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae24e3dc-51d0-4a00-abf9-cae307d7bd62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnimalType      int64\n",
       "Class           int64\n",
       "Fat             int64\n",
       "Weight        float64\n",
       "AgeMonths     float64\n",
       "Remark         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing data not used in training models \n",
    "X = carcass_df.copy()\n",
    "X = X.drop(['Group', \n",
    "            'Killnumber', \n",
    "            'KillDate', \n",
    "            'WeightWarm', \n",
    "            'ClassificationTime', \n",
    "            'PartCassation'], axis=1)\n",
    "\n",
    "# Normalizing the numerical data \n",
    "X[['Weight', 'AgeMonths']] = preprocessing.normalize(\n",
    "    X[['Weight', 'AgeMonths']])\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "709d0f92-6215-4c3d-86e0-ef21b26e53d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weight                float64\n",
       "AgeMonths             float64\n",
       "(Remark, 113\\n589)       bool\n",
       "(Remark, 338\\n588)       bool\n",
       "(Remark, 338\\n589)       bool\n",
       "(Remark, 339\\n588)       bool\n",
       "(Remark, 339\\n589)       bool\n",
       "(Remark, 339\\n590)       bool\n",
       "(Remark, 340\\n589)       bool\n",
       "(Remark, 588)            bool\n",
       "(Remark, 589)            bool\n",
       "(Remark, 590)            bool\n",
       "(Remark, 77\\n589)        bool\n",
       "(Remark, 77\\n590)        bool\n",
       "(Class, 4)               bool\n",
       "(Class, 5)               bool\n",
       "(Class, 6)               bool\n",
       "(Class, 7)               bool\n",
       "(Class, 8)               bool\n",
       "(Class, 9)               bool\n",
       "(Class, 10)              bool\n",
       "(Class, 11)              bool\n",
       "(Fat, 3)                 bool\n",
       "(Fat, 4)                 bool\n",
       "(Fat, 5)                 bool\n",
       "(Fat, 6)                 bool\n",
       "(Fat, 7)                 bool\n",
       "(Fat, 8)                 bool\n",
       "(Fat, 9)                 bool\n",
       "(Fat, 10)                bool\n",
       "(AnimalType, 212)        bool\n",
       "(AnimalType, 216)        bool\n",
       "(AnimalType, 218)        bool\n",
       "(AnimalType, 219)        bool\n",
       "(AnimalType, 222)        bool\n",
       "(AnimalType, 224)        bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding for categorical data\n",
    "\n",
    "# Using One Hot Encoding to add the top ten remarks as binary features \n",
    "remark_sorted = X['Remark'].value_counts()\n",
    "top_remarks = []\n",
    "nr_of_remarks = 12\n",
    "for key in range(nr_of_remarks):\n",
    "    top_remarks.append(remark_sorted.keys()[key])\n",
    "    \n",
    "df_encoded = pd.get_dummies(X['Remark'], columns=['Remark'])\n",
    "for col in df_encoded.columns:\n",
    "    if col in top_remarks:\n",
    "        X['Remark',col] = df_encoded[col]\n",
    "\n",
    "X = X.drop(['Remark'], axis=1)\n",
    "\n",
    "# Using One Hot Encoding to add the top ten Classes as binary features \n",
    "class_sorted = X['Class'].value_counts()\n",
    "top_class = []\n",
    "nr_of_classes = 8\n",
    "for key in range(nr_of_classes):\n",
    "    top_class.append(class_sorted.keys()[key])\n",
    "        \n",
    "df_encoded = pd.get_dummies(X['Class'], columns=['Class'])\n",
    "for col in df_encoded.columns:\n",
    "    if col in top_class:\n",
    "        X['Class',col] = df_encoded[col]\n",
    "\n",
    "X = X.drop(['Class'], axis=1)\n",
    "\n",
    "# Using One Hot Encoding to add the top ten Fats as binary features \n",
    "fat_sorted = X['Fat'].value_counts()\n",
    "top_fat = []\n",
    "nr_of_fats = 8\n",
    "for key in range(nr_of_fats):\n",
    "    top_fat.append(fat_sorted.keys()[key])\n",
    "        \n",
    "df_encoded = pd.get_dummies(X['Fat'], columns=['Fat'])\n",
    "for col in df_encoded.columns:\n",
    "    if col in top_fat:\n",
    "        X['Fat',col] = df_encoded[col]\n",
    "\n",
    "X = X.drop(['Fat'], axis=1)\n",
    "\n",
    "# Using One Hot Encoding to add AnimalType as binary features \n",
    "df_encoded = pd.get_dummies(X['AnimalType'], columns=['AnimalType'])\n",
    "for col in df_encoded.columns:\n",
    "    X['AnimalType',col] = df_encoded[col]\n",
    "\n",
    "X = X.drop(['AnimalType'], axis=1)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49ee83aa-6310-4cbd-a5b9-8aa35c7161e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = carcass_df['Group'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af0150d8-b8cc-4599-b673-8b13daaf3813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline random classifier\n",
    "dummy_clf = DummyClassifier(strategy='uniform', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd6c9726-62ff-41f1-8735-a05815508397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold parametrar: KFold(n_splits=10, random_state=42, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "# Setting k-fold parameters used in the cross validation\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "print(f\"kfold parametrar: {kf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4462e-c868-45e1-b89b-9e58fd1bd356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross validating the model:  60%|█████████████████████▌              | 6/10 [00:01<00:00,  5.23it/s]"
     ]
    }
   ],
   "source": [
    "# Using cross validation to train and test models on set of performance mesurements \n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "result = pd.DataFrame()\n",
    "nr_of_iterations = range(10)\n",
    "# The cross validation is set to using k-fold and a 1 to 10 split,\n",
    "# which is then repeated 10 times resulting in 100 models beeing trained and evaluated.\n",
    "for i in tqdm(nr_of_iterations, total=len(nr_of_iterations), ncols = 100, \n",
    "              desc =\"Cross validating the model\"):\n",
    "    cross_score = cross_validate(dummy_clf,\n",
    "                        X, y, \n",
    "                        scoring=scoring, \n",
    "                        cv=kf)\n",
    "    scores_df = pd.DataFrame.from_dict(cross_score)\n",
    "    frames = [result, scores_df]\n",
    "    result = pd.concat(frames)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775aac6-04ee-42a4-b88f-33e6620217a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261ddcd-7613-4448-a3e4-33418f55f469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.to_csv('DummyTestResults.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217e228-3581-43e8-8633-44f37f3918c4",
   "metadata": {},
   "source": [
    "My estimated average accuracy of 83.5% is not the same as the dummy classifiers 9.2%. \n",
    "I have tried to find out why and it seems that sklearn uses another formula for its [accuracy](https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score). \n",
    "\n",
    "Calculating the accuracy using this formula gives a similar result as of that the sklearns dummy classifier gets.\n",
    "\n",
    "Their formula could be divided into two: \n",
    "* The first part is 1 divided by the population ``1/population`` \n",
    "* And the number of times the classifier predicts something correctly, calculated by summing the indicator function which returns 1 if something is classified correctly and 0 if something is wrongly classified. This indicator function should in our case return 1 every 11th time following that there are 11 clusters that are evenly distributed, which because this is for the entire population should give us 1 ``(1/number of clusters) * population size`` times. Which can be shortened to ``population/number of clusters`` \n",
    "\n",
    "Multiplying these then gives the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ba791-20ee-454c-bd4f-17359d95bd86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn_accuracy = (1/P)*(P/C)\n",
    "print(sklearn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce469c-9170-4aaa-9d91-c5722b57c5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
